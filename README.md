   # README-BigData-Kel3
Laporan README Kelompok 3 Kelas Big Data A

LAPORAN PROJECT AKHIR (EAS) "Simulasi Rekayasa Data Real-Time dan Pemodelan Prediktif Saham Unggulan AS Menggunakan PySpark"
# ğŸ“Š Big Data Project - Kelompok 3

Proyek ini dibuat sebagai bagian dari tugas akhir mata kuliah **Big Data (EAS)** dengan topik:

> **REAL-TIME DATA ENGINEERING AND PREDICTIVE MODELING FOR TOP LEADING COMPANY**

---

## ğŸ‘¥ Kelompok 3
- Sigit Triyono (23083010071)
- Raditya Hylmi Maulana Putra (23083010083)  
- Muhammad Maulana Yusuf (23083010094)  
- Daffa Maulana Briliansyah (23083010098)

---

## ğŸ¯ Tujuan Proyek
Membangun sistem end-to-end yang mampu:
- Mengalirkan data historikal saham secara simulasi real-time menggunakan Kafka.
- Memproses data tersebut dengan KafkaConsumer.
- Memprediksi pergerakan harga saham menggunakan model time series.
- Menampilkan hasil dalam bentuk dashboard interaktif.

---

## âœ¨ Fitur-Fitur Utama

âœ… **Simulasi Real-Time Data Streaming** menggunakan Kafka  
ğŸ”„ **Processing & Cleaning** data dengan Python dan PySpark  
ğŸ“ˆ **Prediksi Harga Saham** menggunakan model ARIMA (time series)  
ğŸ“Š **Dashboard Interaktif** untuk menampilkan:
- Persentase saham naik/turun  
- Top 5 gainers dan losers  
- Volume spike terbesar  
- Tren harga saham utama (TSLA, AAPL, AMZN, dll)

---
## ğŸ§± Arsitektur Sistem

1. **Data Ingestion:** Yahoo Finance API â†’ Kafka (simulasi real-time)
2. **Real-Time Processing:** KafkaConsumer
3. **Storage:** PostgreSQL
4. **Machine Learning:** Model ARIMA / regresi (PySpark MLlib)
5. **Visualization:** Metabase & Streamlit Dashboard

---
## ğŸ§° Teknologi yang Digunakan
| Komponen            | Teknologi                      |
|---------------------|-------------------------------|
| Data Ingestion      | Yahoo Finance API, Apache Kafka |
| Stream Processing   | (KafkaConsumer) + psycopg2 |
| Data Storage        | PostgreSQL                     |
| Machine Learning    | PySpark MLlib (Regression)     |
| Visualisasi         | Metabase, Streamlit            |
| Infrastruktur       | Docker, Python                 |

---

## ğŸ§ª Metodologi

1. **Pengambilan Data:**  
   Mengambil data historikal saham (50 top US companies) dari Yahoo Finance selama 1 bulan terakhir.

2. **Simulasi Streaming:**  
   Data dikirim bertahap ke Kafka agar seolah-olah real-time.

3. **Stream Processing:**  
   KafkaConsumer melakukan cleaning dan transformasi lalu menyimpan ke PostgreSQL.

4. **Modeling:**  
   Membangun model prediksi harga saham dengan regresi atau ARIMA.

5. **Visualisasi:**  
   Dashboard interaktif menggunakan Metabase & Streamlit.

---

Panduan Setup
1. Prasyarat
- Python 3.8+
- Docker & Docker Compose
- Kafka (melalui Docker)
- PostgreSQL (melalui Docker)

2. Instalasi & Setup

| docker-compose up -d |

Docker akan menjalankan:
- Kafka (Broker & Zookeeper)
- PostgreSQL (db: stockdb)
- Metabase (localhost:3000)

---
## ğŸ“ Struktur Folder

â”œâ”€â”€ data/ # Dataset saham (CSV)
â”œâ”€â”€ kafka_stream/ # Script simulasi Kafka Producer
â”œâ”€â”€ spark_streaming/ # PySpark structured streaming
â”œâ”€â”€ modeling/ # Notebook ML model (ARIMA, Regression)
â”œâ”€â”€ visualization/ # Streamlit & Metabase config
â”œâ”€â”€ docker-compose.yml # Konfigurasi Docker
â””â”€â”€ README.md # Dokumentasi proyek
